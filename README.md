ğŸ“˜ Deep Generative Models From Scratch â€” DCGAN + DCVAE on MNIST

A PyTorch implementation of DCGAN and Deep Convolutional VAE, explores generative modelling, training curves and stability, latent space analysis and visualization techniques.

ğŸš€ Models

ğŸ”· DCGAN (Deep Convolutional Generative Adversarial Network)

a) Generator (G)

Purpose: Transform random Gaussian noise into realistic MNIST digits. The generator learns â€œhow to draw digitsâ€ by fooling the discriminator

Input: 100-dimensional noise vector

Upsampling using ConvTranspose2D

BatchNorm for training stability

Final output is 1Ã—28Ã—28 image (MNIST)

Activation: tanh

b) Discriminator (D)

Purpose: Classify images as real or fake. The discriminator learns â€œwhat digits look likeâ€ by detecting artifacts in generator outputs.

Input: MNIST or generated image

Downsampling CNN

LeakyReLU activation

No BatchNorm in the first layer

Output: Real/Fake score (BCEWithLogits)

c) Adversarial Training Loop

Generator tries to create images that look real.

Discriminator learns to distinguish real vs fake.

The models compete, eventually improving each other.

This adversarial setup produces high-quality sharp samples, but GANs do not learn an interpretable latent space.


ğŸ”¶ DCVAE (Deep Convolutional Variational Autoencoder)

A Variational Autoencoder learns:

How to encode an image into a smooth latent space,

How to decode a latent vector back into an image.

It models the data distribution using probabilistic encoding.

a) Encoder

Three convolutional layers

Flatten â†’ Linear layers output Î¼ (mean) and logÏƒÂ² (log variance)

Represents each image as a probability distribution over latent space

Latent dimension = 20

Reparameterization Trick: To enable backpropagation through random sampling:

z = Î¼ + Ïƒ * Îµ,   Îµ ~ N(0, I)

b) Decoder

Linear layer expanding latent vector

Transposed-Convolution layers

Output: 1Ã—28Ã—28 MNIST-style reconstruction

Activation: Sigmoid (since MNIST is grayscale 0â€“1)

c) Loss Function = Reconstruction + KL Divergence

The VAE optimizes:

Loss = BCE(Image, Reconstruction) + Î² * KL(q(z|x) || N(0,I))

BCE encourages accurate reconstruction

KL forces the latent space to follow a Gaussian distribution

Î² controls disentanglement (we use Î² = 0.1)

d) Interpretability Advantage

Unlike GANs, VAEs produce:

Smooth latent spaces

Continuous interpolations

Meaningful structure in latent dimensions

Cluster separation (visible in t-SNE plots)


ğŸ“Š Results & Visualizations


ğŸ“ˆ Training Curves (DCGAN)

<img width="1050" height="750" alt="dcgan_training_curve" src="https://github.com/user-attachments/assets/32e323ea-e8a8-42d5-ac48-b076cbbf7ca3" />


Shows the Generator and Discriminator losses over epochs.

Discriminator loss decreasing â†’ D learns to distinguish real/fake

Generator loss stabilizing â†’ G learns to fool D consistently

Balanced curves indicate healthy adversarial training (no mode collapse)


ğŸ“ˆ Training Curves (DCVAE)

<img width="1050" height="750" alt="dcvae_training_curve" src="https://github.com/user-attachments/assets/2eff9bc0-c94c-4876-96ee-ff75e461449b" />

<img width="1050" height="750" alt="dcvae_bce_kl_train" src="https://github.com/user-attachments/assets/fe921637-7cc8-4a9d-8a51-afebe33eabac" />


Plots the total VAE loss (BCE + KL) across epochs.

Overall decreasing trend â†’ network properly converging

BCE reduces â†’ reconstructions improve

KL term stabilizes â†’ latent distribution approaches N(0, 1)

ğŸ” Latent Space (DCVAE)

<img width="1050" height="750" alt="dcvae_latent_tsne" src="https://github.com/user-attachments/assets/80015bd7-e7ac-4dbb-ad89-f694915f62dd" />

<img width="2250" height="750" alt="dcvae_latent_hist" src="https://github.com/user-attachments/assets/c75b706c-f43c-43f6-b6df-1d09728d357b" />


Latent traversals showing interpretable dimensions

Histograms of learned latents approximate a standard Gaussian, which confirms KL regularization is working (Skewed or collapsed distributions would indicate training issues)

t-SNE showing digit clustering indicates that the encoder organizes latent space semantically (Digits with similar structure overlap (e.g., 3 & 5))


ğŸ“¦ Installation

git clone https://github.com/aniruddha-atre/Deep_Generative_Models_MNIST.git

pip install -r requirements.txt

How to Run Training

Train DCGAN:

python -m src.training.train_dcgan

Train DCVAE:

python -m src.training.train_dcvae

Plots and samples will be auto-generated.
